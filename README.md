
# countmore

### disclaimer: this project is inspired by @karpathy's [makemore](https://github.com/karpathy/makemore) project

countmore takes one text file as input, where each line is assumed to be one training thing and that is multiplication!, and generates more multiplication maths like it.
Under the hood, it is trained using a Transformer model (exactly as seen in GPT).

This is not meant to be too heavyweight library with a billion switches and knobs. It is one hackable file, and is mostly intended for educational purposes. [PyTorch](https://pytorch.org) is the only requirement.

### Usage

The included `multiplication-table.txt` dataset, as an example, has multiplication operations from 1 to 2000 generated by [generate-multiplication-table.ipynb](generate-multiplication-table.ipynb).
It looks like:

```
1x1=1
1x2=2
1x3=3
...
1x20=20
2x1=2
...
2000x20=40000
```

Let's point the script at it:

```bash
$ python countmore-multiply.py -i multiplication-table.txt -o multiplication
```

Training progress and logs and model will all be saved to the working directory `multiplication`.
The default model is a super tiny 200K param transformer;
Many more training configurations are available - see the argparse and read the code.
Training does not require any special hardware, it runs on my Macbook Air and will run on anything else, but if you have a GPU then training will fly faster.
As training progresses the script will print some samples throughout.
However, if you'd like to sample manually, you can use the `--sample-only` flag, e.g. in a separate terminal do:

```bash
$ python countmore-multiply.py -i multiplication-table.txt -o multiplication --sample-only
```

Have fun!

### License

MIT
